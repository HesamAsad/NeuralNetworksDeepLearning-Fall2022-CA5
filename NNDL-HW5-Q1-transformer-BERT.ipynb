{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NNDL - HW5\n",
        "## Transformers\n",
        "### Hesam Asadollahzadeh & Masoud Tahmasbi Fard"
      ],
      "metadata": {
        "id": "PQgxwgvYg1M4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVQ9Q4lw4_XA"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown 15UGzRAuH9ih_TJI-slSwIjjoNSoqSZvE\n",
        "! unzip reviews.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SejEa_HiaAA",
        "outputId": "771679b7-064d-4d2a-d3aa-ae1dcfc69d9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15UGzRAuH9ih_TJI-slSwIjjoNSoqSZvE\n",
            "To: /content/reviews.zip\n",
            "100% 19.8M/19.8M [00:00<00:00, 65.3MB/s]\n",
            "Archive:  reviews.zip\n",
            "  inflating: train_reviews.csv       \n",
            "  inflating: test_reviews.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code"
      ],
      "metadata": {
        "id": "YuLo-YB4mzaj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7xU1WDCtLvd"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prl-PotP4gNl"
      },
      "source": [
        "class MultiHeadAttention(layers.Layer):\n",
        "    def __init__(self, hidden_size, num_heads):\n",
        "\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_heads = num_heads\n",
        "        self.projection_dim = hidden_size // num_heads\n",
        "        self.Q = layers.Dense(hidden_size)\n",
        "        self.K = layers.Dense(hidden_size)\n",
        "        self.V = layers.Dense(hidden_size)\n",
        "        self.out = layers.Dense(hidden_size)\n",
        "\n",
        "    def attention(self, query, key, value, mask):\n",
        "        \n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs, att_mask=None):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.separate_heads(self.Q(inputs)  , batch_size)  \n",
        "        key = self.separate_heads(self.K(inputs), batch_size)  \n",
        "        value = self.separate_heads(self.V(inputs) , batch_size) \n",
        "        attention, self.att_weights = self.attention(query, key, value, att_mask)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.hidden_size))\n",
        "        output = self.out(concat_attention)  \n",
        "        return output"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCVLJBv951nW"
      },
      "source": [
        "#### Feed-Forward Sub-Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRnFXb0WwwSB"
      },
      "source": [
        "Unlike the original transformer, BERT uses \"GELU\" activation function. In this part you should implement the GELU activation function based on the paper provided to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzD7BjELQ--j"
      },
      "source": [
        "@tf.function\n",
        "def GELU(x):\n",
        "    cdf = 0.5 * (1.0 + tf.math.tanh(tf.math.sqrt(2.0/math.pi)*(x + 0.044715*x*x*x)))\n",
        "    return x * cdf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqd6wedZXxzD"
      },
      "source": [
        "class FFN(layers.Layer):\n",
        "    def __init__(self, intermediate_size, hidden_size, drop_rate):\n",
        "        super(FFN, self).__init__()\n",
        "        self.intermediate = layers.Dense(intermediate_size, activation=GELU, kernel_initializer=TruncatedNormal(stddev=0.02))\n",
        "        self.out = layers.Dense(hidden_size, kernel_initializer=TruncatedNormal(stddev=0.02))\n",
        "        self.drop = layers.Dropout(drop_rate)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = self.intermediate(inputs)\n",
        "        out = self.drop(out)\n",
        "        out = self.out(out)\n",
        "        return out"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDlwb3Ea6Aqc"
      },
      "source": [
        "#### Add & Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4-UMLpDUkFa"
      },
      "source": [
        "In this part implement the add & norm blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TtnesNMOHUF"
      },
      "source": [
        "class AddNorm(layers.Layer):\n",
        "    def __init__(self, LNepsilon, drop_rate): \n",
        "        super(AddNorm, self).__init__()\n",
        "        self.LN = layers.LayerNormalization(epsilon=LNepsilon)\n",
        "        self.dropout = layers.Dropout(drop_rate)\n",
        "\n",
        "    def call(self, sub_layer_in, sub_layer_out):\n",
        "        return self.LN(self.dropout(sub_layer_out) + sub_layer_in)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKqyg0J_WuTv"
      },
      "source": [
        "#### Residual connections\n",
        "\n",
        "Now put together all parts and build the encoder with the residual connections\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16zvGFBo_uaQ"
      },
      "source": [
        "class Encoder(layers.Layer):\n",
        "    def __init__(self, hidden_size, num_heads, intermediate_size, drop_rate=0.1, LNepsilon=1e-12):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.attention = MultiHeadAttention(hidden_size, num_heads)\n",
        "        self.addnorm1 = AddNorm(LNepsilon, drop_rate)\n",
        "        self.ffn = FFN(intermediate_size, hidden_size, drop_rate)\n",
        "        self.addnorm2 = AddNorm(LNepsilon, drop_rate)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        Y = self.addnorm1(inputs, self.attention(inputs, mask))\n",
        "        return self.addnorm2(Y, self.ffn(Y))\n",
        "\n",
        "    def compute_mask(self, x, mask=None):\n",
        "        return tf.not_equal(x, 0)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umQ878ho-6Hp"
      },
      "source": [
        "### BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTW-F4t9_x24"
      },
      "source": [
        "class BertEmbedding(layers.Layer):\n",
        "\n",
        "    def __init__(self, vocab_size, maxlen, hidden_size):\n",
        "\n",
        "      super(BertEmbedding, self).__init__()\n",
        "      self.TokEmb = layers.Embedding(input_dim=vocab_size, output_dim=hidden_size, mask_zero=True)\n",
        "      self.PosEmb = layers.Embedding(input_dim=maxlen, output_dim=hidden_size)\n",
        "      self.LN = layers.LayerNormalization(epsilon=1e-12)\n",
        "      self.dropout = layers.Dropout(0.1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        maxlen = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        out = self.TokEmb(inputs)\n",
        "        out = out + self.PosEmb(positions)\n",
        "        return self.dropout(self.LN(out))\n",
        "\n",
        "    def compute_mask(self, x, mask=None):\n",
        "      m = 1-tf.cast(self.TokEmb.compute_mask(x), tf.float32)\n",
        "      m = m[:, tf.newaxis, tf.newaxis, :]\n",
        "      return m"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPjWqcH-ytQP"
      },
      "source": [
        "The \"pooler\" is the last layer you need to put in place.\n",
        "For each input sentence, the pooler changes the hidden states of the last encoder layer (which have the shape [batch size, sequence lenght, hidden size]) into a vector representation (which has the shape [batch size, hidden size]).\n",
        "The pooler does this by giving a dense layer the hidden state that goes with the first token, which is a special token at the beginning of each sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O719umhMz_UH"
      },
      "source": [
        "class Pooler(layers.Layer):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(Pooler, self).__init__()\n",
        "        self.dense = layers.Dense(hidden_size, activation='tanh')\n",
        "\n",
        "    def call(self, encoder_out):\n",
        "        # first_token_tensor = hidden_states[:, 0]\n",
        "        return self.dense(inputs=encoder_out)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P8zt_tFojZY"
      },
      "source": [
        "Now you should complete the **create_BERT** function in the cell below. This function gets BERT's hyper-parameters as its inputs and return a BERT model. \n",
        "Note that the returned model must have two outputs (just like the pre-trained BERTs): \n",
        "- The hidden states of the last encoder layer\n",
        "- Output of the pooler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9tD7UtNfZ4p"
      },
      "source": [
        "def create_BERT(vocab_size, maxlen, hidden_size, num_layers, num_att_heads, intermediate_size, drop_rate=0.1):\n",
        "    \"\"\"\n",
        "    creates a BERT model based on the arguments provided\n",
        "\n",
        "        Arguments:\n",
        "        vocab_size: number of words in the vocabulary\n",
        "        maxlen: maximum length of each sentence\n",
        "        hidden_size: dimension of the hidden state of each encoder layer\n",
        "        num_layers: number of encoder layers\n",
        "        num_att_heads: number of attention heads in the multi-headed attention layer\n",
        "        intermediate_size: dimension of the intermediate layer in the feed-forward sublayer of the encoders\n",
        "        drop_rate: dropout rate of all the dropout layers used in the model\n",
        "        returns: \n",
        "        model\n",
        "    \"\"\"\n",
        "    inputs = tf.keras.Input(shape=(maxlen,))\n",
        "    emb = BertEmbedding(vocab_size, maxlen, hidden_size)\n",
        "    out = emb(inputs)\n",
        "    for i in range(num_layers):\n",
        "        enc = Encoder(hidden_size, num_att_heads, intermediate_size, drop_rate)\n",
        "        out = enc(out)\n",
        "    pooler = Pooler(hidden_size)\n",
        "    out = keras.layers.Dense(1, activation='sigmoid')(keras.layers.Flatten()(pooler(out)))\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=out) \n",
        "\n",
        "    return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKBEBTI6sFKu"
      },
      "source": [
        "We will use the Rotten tomatoes critic reviews dataset for this assignment. The zip file is provided to you. Unzip it and run the cells below to split the dataset in training and test sets and prepare it for feeding to the bert model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUn-48AVXbfR"
      },
      "source": [
        "train_reviews, test_reviews = pd.read_csv('train_reviews.csv').values[:, 1:], pd.read_csv('test_reviews.csv').values[:, 1:]\n",
        "(train_texts, train_labels), (test_texts, test_labels)  = (train_reviews[:,0],train_reviews[:,1]), (test_reviews[:,0],test_reviews[:,1]) \n",
        "train_texts = [s.lower() for s in train_texts]\n",
        "test_texts = [s.lower() for s in test_texts] \n",
        "aprx_vocab_size = 20000\n",
        "cls_token = '[cls]'\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(corpus_generator=train_texts,\n",
        "                                                        target_vocab_size=aprx_vocab_size,\n",
        "                                                        reserved_tokens=[cls_token])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhTvBa9ntO7b"
      },
      "source": [
        "In the following cell, you need to complete the implementation of the encode_sentence function. This function takes as input a sentence and an integer representing the maximum length of the sentence and returns a list of token ids. To implement this function, follow these steps:\n",
        "\n",
        "-Use the trained tokenizer to encode the input sentence and obtain a list of token ids.\n",
        "\n",
        "-Pad the token id list with zeros to the maximum length specified.\n",
        "\n",
        "-Prepend the id of the special token to the beginning of the token id list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzO4yiJSmIRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988fcbee-1c3d-493a-bb2f-568f99fee09c"
      },
      "source": [
        "def encode_sentence(s, maxlen):\n",
        "    tok_id_list = tokenizer.encode(cls_token + s)\n",
        "    tok_id_list = tf.keras.utils.pad_sequences([tok_id_list], maxlen, padding='post')\n",
        "    return tok_id_list[0]\n",
        "\n",
        "print(encode_sentence('I liked this movie', 32))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    1 19779 19738  2252    18    67     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL-PTRJPYnPb"
      },
      "source": [
        "MAXLEN = 32\n",
        "x_train = np.array([encode_sentence(x, MAXLEN) for x in train_texts], dtype=np.int64)\n",
        "x_test = np.array([encode_sentence(x, MAXLEN) for x in test_texts], dtype=np.int64)\n",
        "y_train = train_labels.astype(np.int64)\n",
        "y_test = test_labels.astype(np.int64)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBirx1Fbvv-k"
      },
      "source": [
        "Now use the functional api and the **create_BERT** function you implemented earlier to create a classifier for the movie reviews dataset.\n",
        "Note that the intermediate layer in the feed-forward sub-layer of the encoders is set to $4\\times H$ in the original BERT implementation, where $H$ is the hidden layer size. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZOW4L9gBqvc"
      },
      "source": [
        "hidden_size = 768\n",
        "num_heads = 12\n",
        "num_layers = 12\n",
        "vocab_size = tokenizer.vocab_size  \n",
        "\n",
        "model = create_BERT(vocab_size, MAXLEN, hidden_size, num_layers, num_heads, num_heads*4)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwBQt1bFBwYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951de271-42e3-434c-e77f-bd550368d08a"
      },
      "source": [
        "model.compile(tf.keras.optimizers.Adam(learning_rate=5e-5), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 32)]              0         \n",
            "                                                                 \n",
            " bert_embedding_4 (BertEmbed  (None, 32, 768)          15356928  \n",
            " ding)                                                           \n",
            "                                                                 \n",
            " encoder_48 (Encoder)        (None, 32, 768)           2439984   \n",
            "                                                                 \n",
            " encoder_49 (Encoder)        (None, 32, 768)           2439984   \n",
            "                                                                 \n",
            " encoder_50 (Encoder)        (None, 32, 768)           2439984   \n",
            "                                                                 \n",
            " encoder_51 (Encoder)        (None, 32, 768)           2439984   \n",
            "                                                                 \n",
            " encoder_52 (Encoder)        (None, 32, 768)           2439984   \n",
            "                                                                 \n",
            " encoder_53 (Encoder)        (None, 32, 768)           2439984   \n",
            "                                                                 \n",
            " encoder_54 (Encoder)        (None, 32, 768)           2439984   \n",
            "                                                                 \n",
            " encoder_55 (Encoder)        (None, 32, 768)           2439984   \n",
            "                                                                 \n",
            " encoder_56 (Encoder)        (None, 32, 768)           2439984   \n",
            "                                                                 \n",
            " encoder_57 (Encoder)        (None, 32, 768)           2439984   \n",
            "                                                                 \n",
            " encoder_58 (Encoder)        (None, 32, 768)           2439984   \n",
            "                                                                 \n",
            " encoder_59 (Encoder)        (None, 32, 768)           2439984   \n",
            "                                                                 \n",
            " pooler_4 (Pooler)           (None, 32, 768)           590592    \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 24576)             0         \n",
            "                                                                 \n",
            " dense_369 (Dense)           (None, 1)                 24577     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,251,905\n",
            "Trainable params: 45,251,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IwB37mHByJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2902c90d-d74c-41f1-b7bc-3e92643248df"
      },
      "source": [
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=128,\n",
        "    epochs=2,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1970/1970 [==============================] - 832s 414ms/step - loss: 0.5228 - accuracy: 0.7315 - val_loss: 0.4691 - val_accuracy: 0.7775\n",
            "Epoch 2/2\n",
            "1970/1970 [==============================] - 807s 410ms/step - loss: 0.4244 - accuracy: 0.8000 - val_loss: 0.4587 - val_accuracy: 0.7873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(np.array([encode_sentence(\"I liked this moive\".lower(), MAXLEN)], dtype=np.int64))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ftjISpW89bJ",
        "outputId": "3a7030b3-c924-4f9b-db99-a3a3898a692f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.95685554]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPfMQS1ZsHHk"
      },
      "source": [
        "### Attention Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwGoqnHXadiF",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "512d41e4-3fac-4090-b386-7391c7ca0e0e"
      },
      "source": [
        "#@title Run this!\n",
        "import sys\n",
        "\n",
        "!test -d bertviz_repo && echo \"FYI: bertviz_repo directory already exists, to pull latest version uncomment this line: !rm -r bertviz_repo\"\n",
        "# !rm -r bertviz_repo # Uncomment if you need a clean pull from repo\n",
        "!test -d bertviz_repo || git clone https://github.com/jessevig/bertviz bertviz_repo\n",
        "if not 'bertviz_repo' in sys.path:\n",
        "  sys.path += ['bertviz_repo']\n",
        "\n",
        "from bertviz import head_view\n",
        "\n",
        "def call_html():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n",
        "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bertviz_repo'...\n",
            "remote: Enumerating objects: 1625, done.\u001b[K\n",
            "remote: Counting objects: 100% (322/322), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 1625 (delta 227), reused 221 (delta 209), pack-reused 1303\u001b[K\n",
            "Receiving objects: 100% (1625/1625), 198.36 MiB | 29.54 MiB/s, done.\n",
            "Resolving deltas: 100% (1069/1069), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p5EleW-6EaN"
      },
      "source": [
        "In order to use bertviz, we need to obtain the attention weights in the encoders of the BERT model implemented in the previous section. To do this, you need to complete the implementation of the get_att_weights function in the following cell. This function takes as input a model (the trained BERT-based model from the previous section) and a list of tokens (an encoded sentence). Here's what you need to do:\n",
        "\n",
        "-Feed the input token list to the model to generate the attention weights for that input.\n",
        "\n",
        "-Access the att_weights attribute of the MultiHeadAttention sub-layer of each encoder in the model and add them all to a list.\n",
        "\n",
        "-Return the list (which should be a list of Tensors)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUsR5r4Z-Pd7"
      },
      "source": [
        "def get_att_weights(model, tok_id_list):\n",
        "    att_weights = []\n",
        "    out = model(tf.convert_to_tensor(np.array([tok_id_list], dtype=np.int64)))\n",
        "    for i in range(2, 14):\n",
        "        att_weights.append(model.layers[i].attention.att_weights)\n",
        "    return att_weights"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaV7YOtuBQeC"
      },
      "source": [
        "import torch\n",
        "def get_att_tok(model, sent):\n",
        "    maxlen = model.layers[0].input_shape[0][-1]\n",
        "    encoded_toks = encode_sentence(sent, maxlen)\n",
        "    att_weights = get_att_weights(model, encoded_toks)\n",
        "    pad_start_idx = np.min(np.where(np.array(encoded_toks) == 0))\n",
        "    toks = encoded_toks[:pad_start_idx]\n",
        "    atts = []\n",
        "    for att in att_weights:\n",
        "        layer_att = torch.FloatTensor(att[:, :, :pad_start_idx, :pad_start_idx].numpy())\n",
        "    atts.append(layer_att)\n",
        "    toks = [tokenizer.decode([m]) for m in toks]\n",
        "    return toks, atts"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Attention visualization\n",
        "now give a sample sentence in the context of giving your opinion about a movie and visualize the attention. for example \"I liked that movie\""
      ],
      "metadata": {
        "id": "MOhd420dk8Ld"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65xPcS1VIWyc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "14d171fe-3f60-48a4-9b23-27c37bb010f8"
      },
      "source": [
        "sentence = \"I liked this movie because of its scenario\"\n",
        "toks, atts = get_att_tok(model, sentence.lower())\n",
        "call_html()\n",
        "head_view(atts, toks, layer=0)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
              "        <script>\n",
              "          requirejs.config({\n",
              "            paths: {\n",
              "              base: '/static/base',\n",
              "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n",
              "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
              "            },\n",
              "          });\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "      \n",
              "        <div id=\"bertviz-7ea494cd150a4b2eb09445ad639ad395\" style=\"font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;\">\n",
              "            <span style=\"user-select:none\">\n",
              "                Layer: <select id=\"layer\"></select>\n",
              "                \n",
              "            </span>\n",
              "            <div id='vis'></div>\n",
              "        </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "/**\n",
              " * @fileoverview Transformer Visualization D3 javascript code.\n",
              " *\n",
              " *\n",
              " *  Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n",
              " *\n",
              " * Change log:\n",
              " *\n",
              " * 12/19/18  Jesse Vig   Assorted cleanup. Changed orientation of attention matrices.\n",
              " * 12/29/20  Jesse Vig   Significant refactor.\n",
              " * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n",
              " * 02/06/21  Jesse Vig   Move require config from separate jupyter notebook step\n",
              " * 05/03/21  Jesse Vig   Adjust height of visualization dynamically\n",
              " * 07/25/21  Jesse Vig   Support layer filtering\n",
              " * 03/23/22  Daniel SC   Update requirement URLs for d3 and jQuery (source of bug not allowing end result to be displayed on browsers)\n",
              " **/\n",
              "\n",
              "require.config({\n",
              "  paths: {\n",
              "      d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min',\n",
              "    jquery: 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
              "  }\n",
              "});\n",
              "\n",
              "requirejs(['jquery', 'd3'], function ($, d3) {\n",
              "\n",
              "    const params = {\"attention\": [{\"name\": null, \"attn\": [[[[0.03126572072505951, 0.031239978969097137, 0.031223030760884285, 0.03125381842255592, 0.031233327463269234, 0.03122883476316929, 0.031218884512782097, 0.03119930811226368, 0.031233977526426315], [0.031265739351511, 0.031239967793226242, 0.031223028898239136, 0.03125383332371712, 0.031233349815011024, 0.03122882731258869, 0.03121887519955635, 0.03119930997490883, 0.03123397007584572], [0.0312657468020916, 0.031239978969097137, 0.03122304193675518, 0.03125379607081413, 0.031233305111527443, 0.03122882731258869, 0.031218893826007843, 0.031199321150779724, 0.031233958899974823], [0.031265739351511, 0.03123999945819378, 0.03122302144765854, 0.031253840774297714, 0.03123336471617222, 0.03122883290052414, 0.03121887519955635, 0.031199295073747635, 0.03123396262526512], [0.0312657356262207, 0.031239954754710197, 0.031223013997077942, 0.03125384822487831, 0.03123333677649498, 0.031228812411427498, 0.031218865886330605, 0.031199298799037933, 0.031233958899974823], [0.03126572072505951, 0.0312399473041296, 0.031223000958561897, 0.03125380724668503, 0.03123331628739834, 0.031228823587298393, 0.031218871474266052, 0.03119928203523159, 0.03123396635055542], [0.03126569837331772, 0.031239982694387436, 0.03122301585972309, 0.03125382959842682, 0.031233329325914383, 0.031228819862008095, 0.031218888238072395, 0.031199295073747635, 0.03123396821320057], [0.03126571327447891, 0.031239937990903854, 0.03122301958501339, 0.03125380724668503, 0.031233295798301697, 0.031228812411427498, 0.031218867748975754, 0.031199293211102486, 0.031233951449394226], [0.031265739351511, 0.03123999573290348, 0.031223027035593987, 0.03125382959842682, 0.031233325600624084, 0.03122882917523384, 0.0312188733369112, 0.031199311837553978, 0.03123396821320057]], [[0.031229669228196144, 0.031201478093862534, 0.03126981481909752, 0.031211914494633675, 0.03124774619936943, 0.03127032890915871, 0.03129136189818382, 0.03127015382051468, 0.0312662273645401], [0.031229672953486443, 0.031201492995023727, 0.03126982972025871, 0.03121192567050457, 0.031247764825820923, 0.03127032145857811, 0.03129136562347412, 0.03127013519406319, 0.0312662310898304], [0.031229672953486443, 0.031201502308249474, 0.03126984089612961, 0.031211942434310913, 0.03124777227640152, 0.031270354986190796, 0.03129136189818382, 0.03127015754580498, 0.03126625344157219], [0.031229672953486443, 0.03120150975883007, 0.031269852072000504, 0.031211916357278824, 0.03124774619936943, 0.031270332634449005, 0.03129133582115173, 0.03127015009522438, 0.03126624971628189], [0.031229672953486443, 0.031201479956507683, 0.0312698632478714, 0.03121194615960121, 0.031247776001691818, 0.0312703512609005, 0.03129138797521591, 0.031270164996385574, 0.031266260892152786], [0.031229685992002487, 0.031201468780636787, 0.0312698669731617, 0.031211944296956062, 0.031247755512595177, 0.031270336359739304, 0.031291358172893524, 0.03127015009522438, 0.0312662310898304], [0.031229671090841293, 0.03120148554444313, 0.031269848346710205, 0.031211931258440018, 0.031247762963175774, 0.031270336359739304, 0.03129136562347412, 0.031270164996385574, 0.0312662348151207], [0.031229641288518906, 0.03120146505534649, 0.031269799917936325, 0.03121192753314972, 0.03124774806201458, 0.031270306557416916, 0.03129136562347412, 0.031270142644643784, 0.0312662236392498], [0.031229669228196144, 0.03120148554444313, 0.03126984089612961, 0.03121194615960121, 0.03124774992465973, 0.03127030283212662, 0.03129136562347412, 0.03127015382051468, 0.03126624971628189]], [[0.031212151050567627, 0.031222937628626823, 0.03121107630431652, 0.031289469450712204, 0.03127351403236389, 0.031246239319443703, 0.0312351007014513, 0.031201155856251717, 0.031263429671525955], [0.031212162226438522, 0.031222917139530182, 0.031211070716381073, 0.031289421021938324, 0.03127352520823479, 0.03124622441828251, 0.03123505972325802, 0.03120117075741291, 0.03126342222094536], [0.031212138012051582, 0.031222930178046227, 0.031211066991090775, 0.03128942474722862, 0.03127352520823479, 0.0312462467700243, 0.03123508021235466, 0.031201155856251717, 0.031263433396816254], [0.031212151050567627, 0.031222939491271973, 0.031211072579026222, 0.03128945827484131, 0.03127352148294449, 0.031246276572346687, 0.031235074624419212, 0.031201131641864777, 0.031263429671525955], [0.03121214173734188, 0.03122294321656227, 0.031211065128445625, 0.03128943219780922, 0.03127351775765419, 0.031246256083250046, 0.03123508207499981, 0.031201152130961418, 0.03126342594623566], [0.03121214173734188, 0.031222930178046227, 0.031211065128445625, 0.03128939867019653, 0.03127351030707359, 0.031246235594153404, 0.031235050410032272, 0.031201137229800224, 0.03126341849565506], [0.031212136149406433, 0.031222928315401077, 0.031211072579026222, 0.03128940612077713, 0.031273528933525085, 0.031246216967701912, 0.03123507834970951, 0.031201181933283806, 0.031263429671525955], [0.031212151050567627, 0.031222933903336525, 0.031211065128445625, 0.031289417296648026, 0.03127352520823479, 0.031246233731508255, 0.03123508393764496, 0.03120114654302597, 0.03126344084739685], [0.03121213987469673, 0.031222930178046227, 0.031211063265800476, 0.03128943592309952, 0.03127352148294449, 0.0312462467700243, 0.03123508021235466, 0.031201152130961418, 0.03126342594623566]], [[0.03126511722803116, 0.03128660470247269, 0.03125835955142975, 0.03125431388616562, 0.03126368671655655, 0.031257301568984985, 0.03123502805829048, 0.03125416114926338, 0.031282197684049606], [0.03126511722803116, 0.031286608427762985, 0.031258370727300644, 0.031254347413778305, 0.031263723969459534, 0.031257323920726776, 0.03123502805829048, 0.03125417232513428, 0.0312822125852108], [0.03126510605216026, 0.03128659352660179, 0.031258370727300644, 0.03125434368848801, 0.031263694167137146, 0.03125732019543648, 0.031235001981258392, 0.03125416859984398, 0.0312822088599205], [0.031265124678611755, 0.031286608427762985, 0.031258389353752136, 0.031254351139068604, 0.03126368299126625, 0.03125731647014618, 0.031235024333000183, 0.03125419467687607, 0.0312822163105011], [0.03126511350274086, 0.03128662332892418, 0.03125837817788124, 0.03125433623790741, 0.03126369044184685, 0.031257327646017075, 0.031235018745064735, 0.03125416487455368, 0.031282223761081696], [0.03126513585448265, 0.03128661587834358, 0.031258393079042435, 0.03125434368848801, 0.031263697892427444, 0.031257323920726776, 0.031235069036483765, 0.03125418350100517, 0.03128223493695259], [0.03126510605216026, 0.03128658980131149, 0.03125837445259094, 0.03125431388616562, 0.03126369044184685, 0.03125732019543648, 0.03123502805829048, 0.031254153698682785, 0.0312822125852108], [0.03126513212919235, 0.03128661587834358, 0.03125838562846184, 0.031254351139068604, 0.03126371279358864, 0.031257305294275284, 0.03123503364622593, 0.03125419840216637, 0.03128223493695259], [0.031265147030353546, 0.03128662705421448, 0.03125839680433273, 0.03125433996319771, 0.031263694167137146, 0.03125732019543648, 0.031235044822096825, 0.031254176050424576, 0.0312822200357914]], [[0.031252652406692505, 0.03127612546086311, 0.03129412233829498, 0.03129366785287857, 0.03129775449633598, 0.031229784712195396, 0.031246084719896317, 0.03125990927219391, 0.03125004842877388], [0.031252648681402206, 0.03127613291144371, 0.031294092535972595, 0.03129366785287857, 0.031297702342271805, 0.031229790300130844, 0.031246060505509377, 0.03125988319516182, 0.031250033527612686], [0.031252648681402206, 0.0312761515378952, 0.031294114887714386, 0.03129366785287857, 0.03129773959517479, 0.031229812651872635, 0.03124610148370266, 0.03125989809632301, 0.03125005587935448], [0.031252674758434296, 0.03127613291144371, 0.031294092535972595, 0.031293656677007675, 0.03129773214459419, 0.031229780986905098, 0.031246094033122063, 0.0312599278986454, 0.03125004097819328], [0.0312526673078537, 0.031276144087314606, 0.03129413351416588, 0.03129366412758827, 0.031297702342271805, 0.03122980333864689, 0.031246086582541466, 0.0312599316239357, 0.03125005587935448], [0.031252652406692505, 0.03127612918615341, 0.031294114887714386, 0.031293656677007675, 0.03129773586988449, 0.031229795888066292, 0.031246060505509377, 0.03125990182161331, 0.031250033527612686], [0.0312526561319828, 0.03127613663673401, 0.03129411116242409, 0.03129366412758827, 0.031297724694013596, 0.031229769811034203, 0.031246086582541466, 0.0312599278986454, 0.031250059604644775], [0.0312526673078537, 0.03127612918615341, 0.03129412233829498, 0.03129367530345917, 0.03129776194691658, 0.03122977539896965, 0.031246095895767212, 0.031259920448064804, 0.03125004470348358], [0.0312526673078537, 0.031276121735572815, 0.03129412978887558, 0.03129367530345917, 0.031297728419303894, 0.031229788437485695, 0.03124605305492878, 0.03125990182161331, 0.031250037252902985]], [[0.03124217316508293, 0.0312558189034462, 0.031249335035681725, 0.03126373887062073, 0.031216224655508995, 0.03128061071038246, 0.03122224099934101, 0.031292740255594254, 0.031314339488744736], [0.03124218061566353, 0.0312558151781559, 0.03124934993684292, 0.03126373142004013, 0.031216217204928398, 0.03128062188625336, 0.031222231686115265, 0.031292740255594254, 0.031314343214035034], [0.031242182478308678, 0.03125583380460739, 0.031249327585101128, 0.031263742595911026, 0.031216206029057503, 0.03128060698509216, 0.03122224286198616, 0.03129273280501366, 0.03131436929106712], [0.03124217316508293, 0.03125584498047829, 0.031249331310391426, 0.03126371651887894, 0.0312162097543478, 0.03128059580922127, 0.03122222237288952, 0.03129274770617485, 0.031314365565776825], [0.03124215267598629, 0.03125583007931709, 0.03124934993684292, 0.031263723969459534, 0.031216202303767204, 0.031280603259801865, 0.031222239136695862, 0.03129275143146515, 0.03131435811519623], [0.031242160126566887, 0.0312558151781559, 0.03124934807419777, 0.031263697892427444, 0.03121619112789631, 0.03128058835864067, 0.031222224235534668, 0.03129273280501366, 0.03131434693932533], [0.031242161989212036, 0.031255822628736496, 0.03124934993684292, 0.03126370534300804, 0.031216192990541458, 0.03128061816096306, 0.03122222051024437, 0.03129274398088455, 0.03131437674164772], [0.031242167577147484, 0.03125583380460739, 0.031249338760972023, 0.031263742595911026, 0.03121621534228325, 0.03128059580922127, 0.03122221864759922, 0.03129272162914276, 0.03131433576345444], [0.031242171302437782, 0.031255848705768585, 0.031249327585101128, 0.031263720244169235, 0.03121621161699295, 0.031280603259801865, 0.031222237274050713, 0.03129275515675545, 0.03131438046693802]], [[0.031272560358047485, 0.031284306198358536, 0.031262196600437164, 0.03124282881617546, 0.03128719702363014, 0.03127950057387352, 0.03128276765346527, 0.031238213181495667, 0.03125493973493576], [0.03127254545688629, 0.03128429874777794, 0.03126218914985657, 0.031242817640304565, 0.03128720074892044, 0.03127950429916382, 0.03128274530172348, 0.031238200142979622, 0.03125490993261337], [0.03127254918217659, 0.031284306198358536, 0.03126221522688866, 0.03124282695353031, 0.03128720074892044, 0.031279515475034714, 0.03128276765346527, 0.03123820573091507, 0.031254932284355164], [0.03127255290746689, 0.03128430247306824, 0.03126221522688866, 0.03124285861849785, 0.031287215650081635, 0.03127951920032501, 0.03128280118107796, 0.03123822994530201, 0.03125493973493576], [0.03127254918217659, 0.03128433600068092, 0.031262192875146866, 0.031242823228240013, 0.031287238001823425, 0.03127950429916382, 0.03128279000520706, 0.031238209456205368, 0.03125494718551636], [0.03127255290746689, 0.03128432482481003, 0.03126218914985657, 0.03124280646443367, 0.03128720819950104, 0.031279511749744415, 0.03128276765346527, 0.03123820386826992, 0.031254928559064865], [0.031272560358047485, 0.031284306198358536, 0.03126221150159836, 0.03124282881617546, 0.03128722310066223, 0.03127950802445412, 0.031282782554626465, 0.031238211318850517, 0.03125492483377457], [0.03127254545688629, 0.03128432109951973, 0.03126220032572746, 0.031242836266756058, 0.03128720074892044, 0.031279485672712326, 0.03128277137875557, 0.03123820759356022, 0.031254950910806656], [0.0312725305557251, 0.031284358352422714, 0.03126218914985657, 0.03124281018972397, 0.03128720819950104, 0.03127950802445412, 0.03128276765346527, 0.03123820386826992, 0.031254950910806656]], [[0.031220851466059685, 0.03127530589699745, 0.031231528148055077, 0.0312381312251091, 0.031245367601513863, 0.03127887472510338, 0.031248008832335472, 0.031265176832675934, 0.0312698632478714], [0.03122084029018879, 0.03127530962228775, 0.031231526285409927, 0.031238090246915817, 0.03124535270035267, 0.03127887845039368, 0.031248003244400024, 0.031265150755643845, 0.03126990422606468], [0.031220832839608192, 0.03127527981996536, 0.031231513246893883, 0.031238103285431862, 0.03124534897506237, 0.031278856098651886, 0.031248005107045174, 0.03126515448093414, 0.0312698669731617], [0.031220817938447, 0.031275276094675064, 0.031231524422764778, 0.031238097697496414, 0.031245317310094833, 0.03127884119749069, 0.03124796785414219, 0.03126516938209534, 0.03126984089612961], [0.031220808625221252, 0.031275276094675064, 0.03123149462044239, 0.03123811073601246, 0.031245311722159386, 0.03127885237336159, 0.031247979030013084, 0.03126514330506325, 0.0312698595225811], [0.031220821663737297, 0.03127529099583626, 0.031231535598635674, 0.031238099560141563, 0.03124532476067543, 0.03127885237336159, 0.031247971579432487, 0.031265147030353546, 0.031269870698451996], [0.03122083656489849, 0.031275276094675064, 0.03123152069747448, 0.03123810887336731, 0.031245337799191475, 0.031278859823942184, 0.03124799206852913, 0.031265173107385635, 0.0312698669731617], [0.03122084215283394, 0.03127528354525566, 0.031231505796313286, 0.031238093972206116, 0.031245332211256027, 0.03127885237336159, 0.031247979030013084, 0.031265173107385635, 0.03126982972025871], [0.03122084215283394, 0.03127528354525566, 0.031231539323925972, 0.03123810887336731, 0.031245341524481773, 0.03127886354923248, 0.03124799020588398, 0.031265176832675934, 0.03126988187432289]], [[0.03129062429070473, 0.03127635642886162, 0.03127134218811989, 0.03128577023744583, 0.03123638406395912, 0.031258318573236465, 0.031237676739692688, 0.03124869428575039, 0.0312579870223999], [0.03129061684012413, 0.031276337802410126, 0.031271349638700485, 0.03128580003976822, 0.031236404553055763, 0.03125834837555885, 0.031237708404660225, 0.031248686835169792, 0.03125796839594841], [0.03129061311483383, 0.0312763936817646, 0.03127134218811989, 0.03128577768802643, 0.031236352398991585, 0.03125834837555885, 0.03123767487704754, 0.031248698011040688, 0.031258001923561096], [0.03129062056541443, 0.031276386231184006, 0.03127133846282959, 0.031285785138607025, 0.03123635984957218, 0.03125833347439766, 0.031237689778208733, 0.03124869056046009, 0.0312579907476902], [0.031290583312511444, 0.03127633035182953, 0.03127133473753929, 0.03128577396273613, 0.031236369162797928, 0.031258344650268555, 0.03123769536614418, 0.031248679384589195, 0.03125796094536781], [0.03129059821367264, 0.03127637505531311, 0.031271349638700485, 0.03128578141331673, 0.031236356124281883, 0.03125835955142975, 0.031237687915563583, 0.031248675659298897, 0.03125796467065811], [0.03129061684012413, 0.03127638250589371, 0.03127136081457138, 0.03128579631447792, 0.031236417591571808, 0.03125835955142975, 0.031237706542015076, 0.031248675659298897, 0.031257979571819305], [0.03129060938954353, 0.03127637505531311, 0.031271349638700485, 0.031285785138607025, 0.031236371025443077, 0.03125833347439766, 0.031237682327628136, 0.03124869614839554, 0.03125796094536781], [0.03129061311483383, 0.03127636760473251, 0.03127133846282959, 0.03128577023744583, 0.031236382201313972, 0.031258344650268555, 0.031237667426466942, 0.031248657032847404, 0.031257957220077515]], [[0.03124801628291607, 0.03126085177063942, 0.031299889087677, 0.031270626932382584, 0.03125791251659393, 0.031246377155184746, 0.0312669463455677, 0.03128940984606743, 0.03125938028097153], [0.031248020008206367, 0.031260889023542404, 0.031299907714128494, 0.031270645558834076, 0.03125790134072304, 0.031246382743120193, 0.03126697987318039, 0.031289417296648026, 0.03125938028097153], [0.031248001381754875, 0.03126085549592972, 0.031299933791160583, 0.03127066418528557, 0.03125791996717453, 0.031246386468410492, 0.0312669612467289, 0.03128940239548683, 0.03125937283039093], [0.031248027458786964, 0.03126088157296181, 0.031299930065870285, 0.03127063810825348, 0.03125790134072304, 0.03124636597931385, 0.031266950070858, 0.03128940239548683, 0.031259384006261826], [0.031247997656464577, 0.03126088157296181, 0.03129991516470909, 0.031270645558834076, 0.03125789389014244, 0.031246373429894447, 0.0312669537961483, 0.03128940239548683, 0.03125936910510063], [0.031248023733496666, 0.031260862946510315, 0.031299933791160583, 0.031270626932382584, 0.03125791251659393, 0.03124636970460415, 0.03126697242259979, 0.031289443373680115, 0.03125938028097153], [0.031247999519109726, 0.03126086667180061, 0.03129992261528969, 0.03127065300941467, 0.031257908791303635, 0.031246375292539597, 0.0312669575214386, 0.031289417296648026, 0.03125938028097153], [0.031248018145561218, 0.03126087039709091, 0.031299933791160583, 0.03127067908644676, 0.03125791996717453, 0.0312463641166687, 0.03126697614789009, 0.03128938749432564, 0.03125938028097153], [0.031248006969690323, 0.031260885298252106, 0.031299907714128494, 0.031270645558834076, 0.031257908791303635, 0.03124638833105564, 0.031266964972019196, 0.03128937631845474, 0.031259387731552124]], [[0.031207947060465813, 0.03125452995300293, 0.031207602471113205, 0.031233226880431175, 0.031241346150636673, 0.03127545863389969, 0.031238239258527756, 0.03125886991620064, 0.031237026676535606], [0.03120795637369156, 0.03125455603003502, 0.03120761178433895, 0.031233206391334534, 0.03124135173857212, 0.03127545118331909, 0.031238248571753502, 0.03125888109207153, 0.031237030401825905], [0.03120797500014305, 0.03125455230474472, 0.031207619234919548, 0.031233210116624832, 0.03124134987592697, 0.03127545490860939, 0.031238263472914696, 0.031258877366781235, 0.031237056478857994], [0.031207958236336708, 0.03125453367829323, 0.031207609921693802, 0.03123321384191513, 0.031241348013281822, 0.03127545118331909, 0.031238233670592308, 0.03125886619091034, 0.031237047165632248], [0.031207958236336708, 0.03125452995300293, 0.031207602471113205, 0.031233202666044235, 0.031241346150636673, 0.03127545863389969, 0.031238246709108353, 0.03125888481736183, 0.03123704344034195], [0.0312079805880785, 0.03125452250242233, 0.03120761178433895, 0.031233226880431175, 0.031241346150636673, 0.03127545118331909, 0.031238282099366188, 0.031258855015039444, 0.031237052753567696], [0.031207958236336708, 0.03125453367829323, 0.031207596883177757, 0.031233221292495728, 0.031241364777088165, 0.031275443732738495, 0.031238248571753502, 0.03125886246562004, 0.031237028539180756], [0.031207986176013947, 0.03125455230474472, 0.031207624822854996, 0.031233197078108788, 0.03124135732650757, 0.03127544745802879, 0.0312382560223341, 0.03125886991620064, 0.031237035989761353], [0.031207982450723648, 0.031254563480615616, 0.031207619234919548, 0.031233223155140877, 0.031241336837410927, 0.03127546235918999, 0.03123825043439865, 0.03125886991620064, 0.031237071380019188]], [[0.031254082918167114, 0.03128425031900406, 0.031229089945554733, 0.031244991347193718, 0.031197194010019302, 0.03127007558941841, 0.03126927465200424, 0.03124711662530899, 0.03125336766242981], [0.03125406801700592, 0.031284257769584656, 0.03122912161052227, 0.03124501183629036, 0.031197167932987213, 0.0312701091170311, 0.031269289553165436, 0.03124714456498623, 0.0312533862888813], [0.03125407174229622, 0.03128422796726227, 0.031229117885231972, 0.03124496154487133, 0.031197184696793556, 0.0312700979411602, 0.031269270926713943, 0.03124712035059929, 0.0312533862888813], [0.03125407174229622, 0.03128424286842346, 0.031229116022586823, 0.03124498389661312, 0.03119717538356781, 0.031270068138837814, 0.031269270926713943, 0.03124709613621235, 0.031253378838300705], [0.031254056841135025, 0.03128424286842346, 0.03122910112142563, 0.03124498948454857, 0.0311972014605999, 0.0312700979411602, 0.031269293278455734, 0.031247131526470184, 0.0312533862888813], [0.03125404193997383, 0.031284209340810776, 0.031229108572006226, 0.03124498389661312, 0.031197182834148407, 0.031270068138837814, 0.031269244849681854, 0.03124711662530899, 0.03125336393713951], [0.03125407174229622, 0.03128427267074585, 0.031229110434651375, 0.031244976446032524, 0.031197194010019302, 0.03127007186412811, 0.031269289553165436, 0.031247105449438095, 0.031253378838300705], [0.03125404939055443, 0.031284231692552567, 0.031229069456458092, 0.03124496154487133, 0.031197182834148407, 0.03127006068825722, 0.03126927465200424, 0.0312470905482769, 0.03125336393713951], [0.03125408664345741, 0.03128425404429436, 0.03122911974787712, 0.03124498762190342, 0.03119720332324505, 0.03127008303999901, 0.031269319355487823, 0.031247127801179886, 0.031253404915332794]]]], \"left_text\": [\"[cls]\", \"i \", \"liked \", \"this \", \"movie \", \"because \", \"of \", \"its \", \"scenario\"], \"right_text\": [\"[cls]\", \"i \", \"liked \", \"this \", \"movie \", \"because \", \"of \", \"its \", \"scenario\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-7ea494cd150a4b2eb09445ad639ad395\", \"layer\": 0, \"heads\": null, \"include_layers\": [0]}; // HACK: {\"attention\": [{\"name\": null, \"attn\": [[[[0.03126572072505951, 0.031239978969097137, 0.031223030760884285, 0.03125381842255592, 0.031233327463269234, 0.03122883476316929, 0.031218884512782097, 0.03119930811226368, 0.031233977526426315], [0.031265739351511, 0.031239967793226242, 0.031223028898239136, 0.03125383332371712, 0.031233349815011024, 0.03122882731258869, 0.03121887519955635, 0.03119930997490883, 0.03123397007584572], [0.0312657468020916, 0.031239978969097137, 0.03122304193675518, 0.03125379607081413, 0.031233305111527443, 0.03122882731258869, 0.031218893826007843, 0.031199321150779724, 0.031233958899974823], [0.031265739351511, 0.03123999945819378, 0.03122302144765854, 0.031253840774297714, 0.03123336471617222, 0.03122883290052414, 0.03121887519955635, 0.031199295073747635, 0.03123396262526512], [0.0312657356262207, 0.031239954754710197, 0.031223013997077942, 0.03125384822487831, 0.03123333677649498, 0.031228812411427498, 0.031218865886330605, 0.031199298799037933, 0.031233958899974823], [0.03126572072505951, 0.0312399473041296, 0.031223000958561897, 0.03125380724668503, 0.03123331628739834, 0.031228823587298393, 0.031218871474266052, 0.03119928203523159, 0.03123396635055542], [0.03126569837331772, 0.031239982694387436, 0.03122301585972309, 0.03125382959842682, 0.031233329325914383, 0.031228819862008095, 0.031218888238072395, 0.031199295073747635, 0.03123396821320057], [0.03126571327447891, 0.031239937990903854, 0.03122301958501339, 0.03125380724668503, 0.031233295798301697, 0.031228812411427498, 0.031218867748975754, 0.031199293211102486, 0.031233951449394226], [0.031265739351511, 0.03123999573290348, 0.031223027035593987, 0.03125382959842682, 0.031233325600624084, 0.03122882917523384, 0.0312188733369112, 0.031199311837553978, 0.03123396821320057]], [[0.031229669228196144, 0.031201478093862534, 0.03126981481909752, 0.031211914494633675, 0.03124774619936943, 0.03127032890915871, 0.03129136189818382, 0.03127015382051468, 0.0312662273645401], [0.031229672953486443, 0.031201492995023727, 0.03126982972025871, 0.03121192567050457, 0.031247764825820923, 0.03127032145857811, 0.03129136562347412, 0.03127013519406319, 0.0312662310898304], [0.031229672953486443, 0.031201502308249474, 0.03126984089612961, 0.031211942434310913, 0.03124777227640152, 0.031270354986190796, 0.03129136189818382, 0.03127015754580498, 0.03126625344157219], [0.031229672953486443, 0.03120150975883007, 0.031269852072000504, 0.031211916357278824, 0.03124774619936943, 0.031270332634449005, 0.03129133582115173, 0.03127015009522438, 0.03126624971628189], [0.031229672953486443, 0.031201479956507683, 0.0312698632478714, 0.03121194615960121, 0.031247776001691818, 0.0312703512609005, 0.03129138797521591, 0.031270164996385574, 0.031266260892152786], [0.031229685992002487, 0.031201468780636787, 0.0312698669731617, 0.031211944296956062, 0.031247755512595177, 0.031270336359739304, 0.031291358172893524, 0.03127015009522438, 0.0312662310898304], [0.031229671090841293, 0.03120148554444313, 0.031269848346710205, 0.031211931258440018, 0.031247762963175774, 0.031270336359739304, 0.03129136562347412, 0.031270164996385574, 0.0312662348151207], [0.031229641288518906, 0.03120146505534649, 0.031269799917936325, 0.03121192753314972, 0.03124774806201458, 0.031270306557416916, 0.03129136562347412, 0.031270142644643784, 0.0312662236392498], [0.031229669228196144, 0.03120148554444313, 0.03126984089612961, 0.03121194615960121, 0.03124774992465973, 0.03127030283212662, 0.03129136562347412, 0.03127015382051468, 0.03126624971628189]], [[0.031212151050567627, 0.031222937628626823, 0.03121107630431652, 0.031289469450712204, 0.03127351403236389, 0.031246239319443703, 0.0312351007014513, 0.031201155856251717, 0.031263429671525955], [0.031212162226438522, 0.031222917139530182, 0.031211070716381073, 0.031289421021938324, 0.03127352520823479, 0.03124622441828251, 0.03123505972325802, 0.03120117075741291, 0.03126342222094536], [0.031212138012051582, 0.031222930178046227, 0.031211066991090775, 0.03128942474722862, 0.03127352520823479, 0.0312462467700243, 0.03123508021235466, 0.031201155856251717, 0.031263433396816254], [0.031212151050567627, 0.031222939491271973, 0.031211072579026222, 0.03128945827484131, 0.03127352148294449, 0.031246276572346687, 0.031235074624419212, 0.031201131641864777, 0.031263429671525955], [0.03121214173734188, 0.03122294321656227, 0.031211065128445625, 0.03128943219780922, 0.03127351775765419, 0.031246256083250046, 0.03123508207499981, 0.031201152130961418, 0.03126342594623566], [0.03121214173734188, 0.031222930178046227, 0.031211065128445625, 0.03128939867019653, 0.03127351030707359, 0.031246235594153404, 0.031235050410032272, 0.031201137229800224, 0.03126341849565506], [0.031212136149406433, 0.031222928315401077, 0.031211072579026222, 0.03128940612077713, 0.031273528933525085, 0.031246216967701912, 0.03123507834970951, 0.031201181933283806, 0.031263429671525955], [0.031212151050567627, 0.031222933903336525, 0.031211065128445625, 0.031289417296648026, 0.03127352520823479, 0.031246233731508255, 0.03123508393764496, 0.03120114654302597, 0.03126344084739685], [0.03121213987469673, 0.031222930178046227, 0.031211063265800476, 0.03128943592309952, 0.03127352148294449, 0.0312462467700243, 0.03123508021235466, 0.031201152130961418, 0.03126342594623566]], [[0.03126511722803116, 0.03128660470247269, 0.03125835955142975, 0.03125431388616562, 0.03126368671655655, 0.031257301568984985, 0.03123502805829048, 0.03125416114926338, 0.031282197684049606], [0.03126511722803116, 0.031286608427762985, 0.031258370727300644, 0.031254347413778305, 0.031263723969459534, 0.031257323920726776, 0.03123502805829048, 0.03125417232513428, 0.0312822125852108], [0.03126510605216026, 0.03128659352660179, 0.031258370727300644, 0.03125434368848801, 0.031263694167137146, 0.03125732019543648, 0.031235001981258392, 0.03125416859984398, 0.0312822088599205], [0.031265124678611755, 0.031286608427762985, 0.031258389353752136, 0.031254351139068604, 0.03126368299126625, 0.03125731647014618, 0.031235024333000183, 0.03125419467687607, 0.0312822163105011], [0.03126511350274086, 0.03128662332892418, 0.03125837817788124, 0.03125433623790741, 0.03126369044184685, 0.031257327646017075, 0.031235018745064735, 0.03125416487455368, 0.031282223761081696], [0.03126513585448265, 0.03128661587834358, 0.031258393079042435, 0.03125434368848801, 0.031263697892427444, 0.031257323920726776, 0.031235069036483765, 0.03125418350100517, 0.03128223493695259], [0.03126510605216026, 0.03128658980131149, 0.03125837445259094, 0.03125431388616562, 0.03126369044184685, 0.03125732019543648, 0.03123502805829048, 0.031254153698682785, 0.0312822125852108], [0.03126513212919235, 0.03128661587834358, 0.03125838562846184, 0.031254351139068604, 0.03126371279358864, 0.031257305294275284, 0.03123503364622593, 0.03125419840216637, 0.03128223493695259], [0.031265147030353546, 0.03128662705421448, 0.03125839680433273, 0.03125433996319771, 0.031263694167137146, 0.03125732019543648, 0.031235044822096825, 0.031254176050424576, 0.0312822200357914]], [[0.031252652406692505, 0.03127612546086311, 0.03129412233829498, 0.03129366785287857, 0.03129775449633598, 0.031229784712195396, 0.031246084719896317, 0.03125990927219391, 0.03125004842877388], [0.031252648681402206, 0.03127613291144371, 0.031294092535972595, 0.03129366785287857, 0.031297702342271805, 0.031229790300130844, 0.031246060505509377, 0.03125988319516182, 0.031250033527612686], [0.031252648681402206, 0.0312761515378952, 0.031294114887714386, 0.03129366785287857, 0.03129773959517479, 0.031229812651872635, 0.03124610148370266, 0.03125989809632301, 0.03125005587935448], [0.031252674758434296, 0.03127613291144371, 0.031294092535972595, 0.031293656677007675, 0.03129773214459419, 0.031229780986905098, 0.031246094033122063, 0.0312599278986454, 0.03125004097819328], [0.0312526673078537, 0.031276144087314606, 0.03129413351416588, 0.03129366412758827, 0.031297702342271805, 0.03122980333864689, 0.031246086582541466, 0.0312599316239357, 0.03125005587935448], [0.031252652406692505, 0.03127612918615341, 0.031294114887714386, 0.031293656677007675, 0.03129773586988449, 0.031229795888066292, 0.031246060505509377, 0.03125990182161331, 0.031250033527612686], [0.0312526561319828, 0.03127613663673401, 0.03129411116242409, 0.03129366412758827, 0.031297724694013596, 0.031229769811034203, 0.031246086582541466, 0.0312599278986454, 0.031250059604644775], [0.0312526673078537, 0.03127612918615341, 0.03129412233829498, 0.03129367530345917, 0.03129776194691658, 0.03122977539896965, 0.031246095895767212, 0.031259920448064804, 0.03125004470348358], [0.0312526673078537, 0.031276121735572815, 0.03129412978887558, 0.03129367530345917, 0.031297728419303894, 0.031229788437485695, 0.03124605305492878, 0.03125990182161331, 0.031250037252902985]], [[0.03124217316508293, 0.0312558189034462, 0.031249335035681725, 0.03126373887062073, 0.031216224655508995, 0.03128061071038246, 0.03122224099934101, 0.031292740255594254, 0.031314339488744736], [0.03124218061566353, 0.0312558151781559, 0.03124934993684292, 0.03126373142004013, 0.031216217204928398, 0.03128062188625336, 0.031222231686115265, 0.031292740255594254, 0.031314343214035034], [0.031242182478308678, 0.03125583380460739, 0.031249327585101128, 0.031263742595911026, 0.031216206029057503, 0.03128060698509216, 0.03122224286198616, 0.03129273280501366, 0.03131436929106712], [0.03124217316508293, 0.03125584498047829, 0.031249331310391426, 0.03126371651887894, 0.0312162097543478, 0.03128059580922127, 0.03122222237288952, 0.03129274770617485, 0.031314365565776825], [0.03124215267598629, 0.03125583007931709, 0.03124934993684292, 0.031263723969459534, 0.031216202303767204, 0.031280603259801865, 0.031222239136695862, 0.03129275143146515, 0.03131435811519623], [0.031242160126566887, 0.0312558151781559, 0.03124934807419777, 0.031263697892427444, 0.03121619112789631, 0.03128058835864067, 0.031222224235534668, 0.03129273280501366, 0.03131434693932533], [0.031242161989212036, 0.031255822628736496, 0.03124934993684292, 0.03126370534300804, 0.031216192990541458, 0.03128061816096306, 0.03122222051024437, 0.03129274398088455, 0.03131437674164772], [0.031242167577147484, 0.03125583380460739, 0.031249338760972023, 0.031263742595911026, 0.03121621534228325, 0.03128059580922127, 0.03122221864759922, 0.03129272162914276, 0.03131433576345444], [0.031242171302437782, 0.031255848705768585, 0.031249327585101128, 0.031263720244169235, 0.03121621161699295, 0.031280603259801865, 0.031222237274050713, 0.03129275515675545, 0.03131438046693802]], [[0.031272560358047485, 0.031284306198358536, 0.031262196600437164, 0.03124282881617546, 0.03128719702363014, 0.03127950057387352, 0.03128276765346527, 0.031238213181495667, 0.03125493973493576], [0.03127254545688629, 0.03128429874777794, 0.03126218914985657, 0.031242817640304565, 0.03128720074892044, 0.03127950429916382, 0.03128274530172348, 0.031238200142979622, 0.03125490993261337], [0.03127254918217659, 0.031284306198358536, 0.03126221522688866, 0.03124282695353031, 0.03128720074892044, 0.031279515475034714, 0.03128276765346527, 0.03123820573091507, 0.031254932284355164], [0.03127255290746689, 0.03128430247306824, 0.03126221522688866, 0.03124285861849785, 0.031287215650081635, 0.03127951920032501, 0.03128280118107796, 0.03123822994530201, 0.03125493973493576], [0.03127254918217659, 0.03128433600068092, 0.031262192875146866, 0.031242823228240013, 0.031287238001823425, 0.03127950429916382, 0.03128279000520706, 0.031238209456205368, 0.03125494718551636], [0.03127255290746689, 0.03128432482481003, 0.03126218914985657, 0.03124280646443367, 0.03128720819950104, 0.031279511749744415, 0.03128276765346527, 0.03123820386826992, 0.031254928559064865], [0.031272560358047485, 0.031284306198358536, 0.03126221150159836, 0.03124282881617546, 0.03128722310066223, 0.03127950802445412, 0.031282782554626465, 0.031238211318850517, 0.03125492483377457], [0.03127254545688629, 0.03128432109951973, 0.03126220032572746, 0.031242836266756058, 0.03128720074892044, 0.031279485672712326, 0.03128277137875557, 0.03123820759356022, 0.031254950910806656], [0.0312725305557251, 0.031284358352422714, 0.03126218914985657, 0.03124281018972397, 0.03128720819950104, 0.03127950802445412, 0.03128276765346527, 0.03123820386826992, 0.031254950910806656]], [[0.031220851466059685, 0.03127530589699745, 0.031231528148055077, 0.0312381312251091, 0.031245367601513863, 0.03127887472510338, 0.031248008832335472, 0.031265176832675934, 0.0312698632478714], [0.03122084029018879, 0.03127530962228775, 0.031231526285409927, 0.031238090246915817, 0.03124535270035267, 0.03127887845039368, 0.031248003244400024, 0.031265150755643845, 0.03126990422606468], [0.031220832839608192, 0.03127527981996536, 0.031231513246893883, 0.031238103285431862, 0.03124534897506237, 0.031278856098651886, 0.031248005107045174, 0.03126515448093414, 0.0312698669731617], [0.031220817938447, 0.031275276094675064, 0.031231524422764778, 0.031238097697496414, 0.031245317310094833, 0.03127884119749069, 0.03124796785414219, 0.03126516938209534, 0.03126984089612961], [0.031220808625221252, 0.031275276094675064, 0.03123149462044239, 0.03123811073601246, 0.031245311722159386, 0.03127885237336159, 0.031247979030013084, 0.03126514330506325, 0.0312698595225811], [0.031220821663737297, 0.03127529099583626, 0.031231535598635674, 0.031238099560141563, 0.03124532476067543, 0.03127885237336159, 0.031247971579432487, 0.031265147030353546, 0.031269870698451996], [0.03122083656489849, 0.031275276094675064, 0.03123152069747448, 0.03123810887336731, 0.031245337799191475, 0.031278859823942184, 0.03124799206852913, 0.031265173107385635, 0.0312698669731617], [0.03122084215283394, 0.03127528354525566, 0.031231505796313286, 0.031238093972206116, 0.031245332211256027, 0.03127885237336159, 0.031247979030013084, 0.031265173107385635, 0.03126982972025871], [0.03122084215283394, 0.03127528354525566, 0.031231539323925972, 0.03123810887336731, 0.031245341524481773, 0.03127886354923248, 0.03124799020588398, 0.031265176832675934, 0.03126988187432289]], [[0.03129062429070473, 0.03127635642886162, 0.03127134218811989, 0.03128577023744583, 0.03123638406395912, 0.031258318573236465, 0.031237676739692688, 0.03124869428575039, 0.0312579870223999], [0.03129061684012413, 0.031276337802410126, 0.031271349638700485, 0.03128580003976822, 0.031236404553055763, 0.03125834837555885, 0.031237708404660225, 0.031248686835169792, 0.03125796839594841], [0.03129061311483383, 0.0312763936817646, 0.03127134218811989, 0.03128577768802643, 0.031236352398991585, 0.03125834837555885, 0.03123767487704754, 0.031248698011040688, 0.031258001923561096], [0.03129062056541443, 0.031276386231184006, 0.03127133846282959, 0.031285785138607025, 0.03123635984957218, 0.03125833347439766, 0.031237689778208733, 0.03124869056046009, 0.0312579907476902], [0.031290583312511444, 0.03127633035182953, 0.03127133473753929, 0.03128577396273613, 0.031236369162797928, 0.031258344650268555, 0.03123769536614418, 0.031248679384589195, 0.03125796094536781], [0.03129059821367264, 0.03127637505531311, 0.031271349638700485, 0.03128578141331673, 0.031236356124281883, 0.03125835955142975, 0.031237687915563583, 0.031248675659298897, 0.03125796467065811], [0.03129061684012413, 0.03127638250589371, 0.03127136081457138, 0.03128579631447792, 0.031236417591571808, 0.03125835955142975, 0.031237706542015076, 0.031248675659298897, 0.031257979571819305], [0.03129060938954353, 0.03127637505531311, 0.031271349638700485, 0.031285785138607025, 0.031236371025443077, 0.03125833347439766, 0.031237682327628136, 0.03124869614839554, 0.03125796094536781], [0.03129061311483383, 0.03127636760473251, 0.03127133846282959, 0.03128577023744583, 0.031236382201313972, 0.031258344650268555, 0.031237667426466942, 0.031248657032847404, 0.031257957220077515]], [[0.03124801628291607, 0.03126085177063942, 0.031299889087677, 0.031270626932382584, 0.03125791251659393, 0.031246377155184746, 0.0312669463455677, 0.03128940984606743, 0.03125938028097153], [0.031248020008206367, 0.031260889023542404, 0.031299907714128494, 0.031270645558834076, 0.03125790134072304, 0.031246382743120193, 0.03126697987318039, 0.031289417296648026, 0.03125938028097153], [0.031248001381754875, 0.03126085549592972, 0.031299933791160583, 0.03127066418528557, 0.03125791996717453, 0.031246386468410492, 0.0312669612467289, 0.03128940239548683, 0.03125937283039093], [0.031248027458786964, 0.03126088157296181, 0.031299930065870285, 0.03127063810825348, 0.03125790134072304, 0.03124636597931385, 0.031266950070858, 0.03128940239548683, 0.031259384006261826], [0.031247997656464577, 0.03126088157296181, 0.03129991516470909, 0.031270645558834076, 0.03125789389014244, 0.031246373429894447, 0.0312669537961483, 0.03128940239548683, 0.03125936910510063], [0.031248023733496666, 0.031260862946510315, 0.031299933791160583, 0.031270626932382584, 0.03125791251659393, 0.03124636970460415, 0.03126697242259979, 0.031289443373680115, 0.03125938028097153], [0.031247999519109726, 0.03126086667180061, 0.03129992261528969, 0.03127065300941467, 0.031257908791303635, 0.031246375292539597, 0.0312669575214386, 0.031289417296648026, 0.03125938028097153], [0.031248018145561218, 0.03126087039709091, 0.031299933791160583, 0.03127067908644676, 0.03125791996717453, 0.0312463641166687, 0.03126697614789009, 0.03128938749432564, 0.03125938028097153], [0.031248006969690323, 0.031260885298252106, 0.031299907714128494, 0.031270645558834076, 0.031257908791303635, 0.03124638833105564, 0.031266964972019196, 0.03128937631845474, 0.031259387731552124]], [[0.031207947060465813, 0.03125452995300293, 0.031207602471113205, 0.031233226880431175, 0.031241346150636673, 0.03127545863389969, 0.031238239258527756, 0.03125886991620064, 0.031237026676535606], [0.03120795637369156, 0.03125455603003502, 0.03120761178433895, 0.031233206391334534, 0.03124135173857212, 0.03127545118331909, 0.031238248571753502, 0.03125888109207153, 0.031237030401825905], [0.03120797500014305, 0.03125455230474472, 0.031207619234919548, 0.031233210116624832, 0.03124134987592697, 0.03127545490860939, 0.031238263472914696, 0.031258877366781235, 0.031237056478857994], [0.031207958236336708, 0.03125453367829323, 0.031207609921693802, 0.03123321384191513, 0.031241348013281822, 0.03127545118331909, 0.031238233670592308, 0.03125886619091034, 0.031237047165632248], [0.031207958236336708, 0.03125452995300293, 0.031207602471113205, 0.031233202666044235, 0.031241346150636673, 0.03127545863389969, 0.031238246709108353, 0.03125888481736183, 0.03123704344034195], [0.0312079805880785, 0.03125452250242233, 0.03120761178433895, 0.031233226880431175, 0.031241346150636673, 0.03127545118331909, 0.031238282099366188, 0.031258855015039444, 0.031237052753567696], [0.031207958236336708, 0.03125453367829323, 0.031207596883177757, 0.031233221292495728, 0.031241364777088165, 0.031275443732738495, 0.031238248571753502, 0.03125886246562004, 0.031237028539180756], [0.031207986176013947, 0.03125455230474472, 0.031207624822854996, 0.031233197078108788, 0.03124135732650757, 0.03127544745802879, 0.0312382560223341, 0.03125886991620064, 0.031237035989761353], [0.031207982450723648, 0.031254563480615616, 0.031207619234919548, 0.031233223155140877, 0.031241336837410927, 0.03127546235918999, 0.03123825043439865, 0.03125886991620064, 0.031237071380019188]], [[0.031254082918167114, 0.03128425031900406, 0.031229089945554733, 0.031244991347193718, 0.031197194010019302, 0.03127007558941841, 0.03126927465200424, 0.03124711662530899, 0.03125336766242981], [0.03125406801700592, 0.031284257769584656, 0.03122912161052227, 0.03124501183629036, 0.031197167932987213, 0.0312701091170311, 0.031269289553165436, 0.03124714456498623, 0.0312533862888813], [0.03125407174229622, 0.03128422796726227, 0.031229117885231972, 0.03124496154487133, 0.031197184696793556, 0.0312700979411602, 0.031269270926713943, 0.03124712035059929, 0.0312533862888813], [0.03125407174229622, 0.03128424286842346, 0.031229116022586823, 0.03124498389661312, 0.03119717538356781, 0.031270068138837814, 0.031269270926713943, 0.03124709613621235, 0.031253378838300705], [0.031254056841135025, 0.03128424286842346, 0.03122910112142563, 0.03124498948454857, 0.0311972014605999, 0.0312700979411602, 0.031269293278455734, 0.031247131526470184, 0.0312533862888813], [0.03125404193997383, 0.031284209340810776, 0.031229108572006226, 0.03124498389661312, 0.031197182834148407, 0.031270068138837814, 0.031269244849681854, 0.03124711662530899, 0.03125336393713951], [0.03125407174229622, 0.03128427267074585, 0.031229110434651375, 0.031244976446032524, 0.031197194010019302, 0.03127007186412811, 0.031269289553165436, 0.031247105449438095, 0.031253378838300705], [0.03125404939055443, 0.031284231692552567, 0.031229069456458092, 0.03124496154487133, 0.031197182834148407, 0.03127006068825722, 0.03126927465200424, 0.0312470905482769, 0.03125336393713951], [0.03125408664345741, 0.03128425404429436, 0.03122911974787712, 0.03124498762190342, 0.03119720332324505, 0.03127008303999901, 0.031269319355487823, 0.031247127801179886, 0.031253404915332794]]]], \"left_text\": [\"[cls]\", \"i \", \"liked \", \"this \", \"movie \", \"because \", \"of \", \"its \", \"scenario\"], \"right_text\": [\"[cls]\", \"i \", \"liked \", \"this \", \"movie \", \"because \", \"of \", \"its \", \"scenario\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-7ea494cd150a4b2eb09445ad639ad395\", \"layer\": 0, \"heads\": null, \"include_layers\": [0]} is a template marker that is replaced by actual params.\n",
              "    const TEXT_SIZE = 15;\n",
              "    const BOXWIDTH = 110;\n",
              "    const BOXHEIGHT = 22.5;\n",
              "    const MATRIX_WIDTH = 115;\n",
              "    const CHECKBOX_SIZE = 20;\n",
              "    const TEXT_TOP = 30;\n",
              "\n",
              "    console.log(\"d3 version\", d3.version)\n",
              "    let headColors;\n",
              "    try {\n",
              "        headColors = d3.scaleOrdinal(d3.schemeCategory10);\n",
              "    } catch (err) {\n",
              "        console.log('Older d3 version')\n",
              "        headColors = d3.scale.category10();\n",
              "    }\n",
              "    let config = {};\n",
              "    initialize();\n",
              "    renderVis();\n",
              "\n",
              "    function initialize() {\n",
              "        config.attention = params['attention'];\n",
              "        config.filter = params['default_filter'];\n",
              "        config.rootDivId = params['root_div_id'];\n",
              "        config.nLayers = config.attention[config.filter]['attn'].length;\n",
              "        config.nHeads = config.attention[config.filter]['attn'][0].length;\n",
              "        config.layers = params['include_layers']\n",
              "\n",
              "        if (params['heads']) {\n",
              "            config.headVis = new Array(config.nHeads).fill(false);\n",
              "            params['heads'].forEach(x => config.headVis[x] = true);\n",
              "        } else {\n",
              "            config.headVis = new Array(config.nHeads).fill(true);\n",
              "        }\n",
              "        config.initialTextLength = config.attention[config.filter].right_text.length;\n",
              "        config.layer_seq = (params['layer'] == null ? 0 : config.layers.findIndex(layer => params['layer'] === layer));\n",
              "        config.layer = config.layers[config.layer_seq]\n",
              "\n",
              "        let layerEl = $(`#${config.rootDivId} #layer`);\n",
              "        for (const layer of config.layers) {\n",
              "            layerEl.append($(\"<option />\").val(layer).text(layer));\n",
              "        }\n",
              "        layerEl.val(config.layer).change();\n",
              "        layerEl.on('change', function (e) {\n",
              "            config.layer = +e.currentTarget.value;\n",
              "            config.layer_seq = config.layers.findIndex(layer => config.layer === layer);\n",
              "            renderVis();\n",
              "        });\n",
              "\n",
              "        $(`#${config.rootDivId} #filter`).on('change', function (e) {\n",
              "            config.filter = e.currentTarget.value;\n",
              "            renderVis();\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function renderVis() {\n",
              "\n",
              "        // Load parameters\n",
              "        const attnData = config.attention[config.filter];\n",
              "        const leftText = attnData.left_text;\n",
              "        const rightText = attnData.right_text;\n",
              "\n",
              "        // Select attention for given layer\n",
              "        const layerAttention = attnData.attn[config.layer_seq];\n",
              "\n",
              "        // Clear vis\n",
              "        $(`#${config.rootDivId} #vis`).empty();\n",
              "\n",
              "        // Determine size of visualization\n",
              "        const height = Math.max(leftText.length, rightText.length) * BOXHEIGHT + TEXT_TOP;\n",
              "        const svg = d3.select(`#${config.rootDivId} #vis`)\n",
              "            .append('svg')\n",
              "            .attr(\"width\", \"100%\")\n",
              "            .attr(\"height\", height + \"px\");\n",
              "\n",
              "        // Display tokens on left and right side of visualization\n",
              "        renderText(svg, leftText, true, layerAttention, 0);\n",
              "        renderText(svg, rightText, false, layerAttention, MATRIX_WIDTH + BOXWIDTH);\n",
              "\n",
              "        // Render attention arcs\n",
              "        renderAttention(svg, layerAttention);\n",
              "\n",
              "        // Draw squares at top of visualization, one for each head\n",
              "        drawCheckboxes(0, svg, layerAttention);\n",
              "    }\n",
              "\n",
              "    function renderText(svg, text, isLeft, attention, leftPos) {\n",
              "\n",
              "        const textContainer = svg.append(\"svg:g\")\n",
              "            .attr(\"id\", isLeft ? \"left\" : \"right\");\n",
              "\n",
              "        // Add attention highlights superimposed over words\n",
              "        textContainer.append(\"g\")\n",
              "            .classed(\"attentionBoxes\", true)\n",
              "            .selectAll(\"g\")\n",
              "            .data(attention)\n",
              "            .enter()\n",
              "            .append(\"g\")\n",
              "            .attr(\"head-index\", (d, i) => i)\n",
              "            .selectAll(\"rect\")\n",
              "            .data(d => isLeft ? d : transpose(d)) // if right text, transpose attention to get right-to-left weights\n",
              "            .enter()\n",
              "            .append(\"rect\")\n",
              "            .attr(\"x\", function () {\n",
              "                var headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
              "                return leftPos + boxOffsets(headIndex);\n",
              "            })\n",
              "            .attr(\"y\", (+1) * BOXHEIGHT)\n",
              "            .attr(\"width\", BOXWIDTH / activeHeads())\n",
              "            .attr(\"height\", BOXHEIGHT)\n",
              "            .attr(\"fill\", function () {\n",
              "                return headColors(+this.parentNode.getAttribute(\"head-index\"))\n",
              "            })\n",
              "            .style(\"opacity\", 0.0);\n",
              "\n",
              "        const tokenContainer = textContainer.append(\"g\").selectAll(\"g\")\n",
              "            .data(text)\n",
              "            .enter()\n",
              "            .append(\"g\");\n",
              "\n",
              "        // Add gray background that appears when hovering over text\n",
              "        tokenContainer.append(\"rect\")\n",
              "            .classed(\"background\", true)\n",
              "            .style(\"opacity\", 0.0)\n",
              "            .attr(\"fill\", \"lightgray\")\n",
              "            .attr(\"x\", leftPos)\n",
              "            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n",
              "            .attr(\"width\", BOXWIDTH)\n",
              "            .attr(\"height\", BOXHEIGHT);\n",
              "\n",
              "        // Add token text\n",
              "        const textEl = tokenContainer.append(\"text\")\n",
              "            .text(d => d)\n",
              "            .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
              "            .style(\"cursor\", \"default\")\n",
              "            .style(\"-webkit-user-select\", \"none\")\n",
              "            .attr(\"x\", leftPos)\n",
              "            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT);\n",
              "\n",
              "        if (isLeft) {\n",
              "            textEl.style(\"text-anchor\", \"end\")\n",
              "                .attr(\"dx\", BOXWIDTH - 0.5 * TEXT_SIZE)\n",
              "                .attr(\"dy\", TEXT_SIZE);\n",
              "        } else {\n",
              "            textEl.style(\"text-anchor\", \"start\")\n",
              "                .attr(\"dx\", +0.5 * TEXT_SIZE)\n",
              "                .attr(\"dy\", TEXT_SIZE);\n",
              "        }\n",
              "\n",
              "        tokenContainer.on(\"mouseover\", function (d, index) {\n",
              "\n",
              "            // Show gray background for moused-over token\n",
              "            textContainer.selectAll(\".background\")\n",
              "                .style(\"opacity\", (d, i) => i === index ? 1.0 : 0.0)\n",
              "\n",
              "            // Reset visibility attribute for any previously highlighted attention arcs\n",
              "            svg.select(\"#attention\")\n",
              "                .selectAll(\"line[visibility='visible']\")\n",
              "                .attr(\"visibility\", null)\n",
              "\n",
              "            // Hide group containing attention arcs\n",
              "            svg.select(\"#attention\").attr(\"visibility\", \"hidden\");\n",
              "\n",
              "            // Set to visible appropriate attention arcs to be highlighted\n",
              "            if (isLeft) {\n",
              "                svg.select(\"#attention\").selectAll(\"line[left-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n",
              "            } else {\n",
              "                svg.select(\"#attention\").selectAll(\"line[right-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n",
              "            }\n",
              "\n",
              "            // Update color boxes superimposed over tokens\n",
              "            const id = isLeft ? \"right\" : \"left\";\n",
              "            const leftPos = isLeft ? MATRIX_WIDTH + BOXWIDTH : 0;\n",
              "            svg.select(\"#\" + id)\n",
              "                .selectAll(\".attentionBoxes\")\n",
              "                .selectAll(\"g\")\n",
              "                .attr(\"head-index\", (d, i) => i)\n",
              "                .selectAll(\"rect\")\n",
              "                .attr(\"x\", function () {\n",
              "                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
              "                    return leftPos + boxOffsets(headIndex);\n",
              "                })\n",
              "                .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n",
              "                .attr(\"width\", BOXWIDTH / activeHeads())\n",
              "                .attr(\"height\", BOXHEIGHT)\n",
              "                .style(\"opacity\", function (d) {\n",
              "                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
              "                    if (config.headVis[headIndex])\n",
              "                        if (d) {\n",
              "                            return d[index];\n",
              "                        } else {\n",
              "                            return 0.0;\n",
              "                        }\n",
              "                    else\n",
              "                        return 0.0;\n",
              "                });\n",
              "        });\n",
              "\n",
              "        textContainer.on(\"mouseleave\", function () {\n",
              "\n",
              "            // Unhighlight selected token\n",
              "            d3.select(this).selectAll(\".background\")\n",
              "                .style(\"opacity\", 0.0);\n",
              "\n",
              "            // Reset visibility attributes for previously selected lines\n",
              "            svg.select(\"#attention\")\n",
              "                .selectAll(\"line[visibility='visible']\")\n",
              "                .attr(\"visibility\", null) ;\n",
              "            svg.select(\"#attention\").attr(\"visibility\", \"visible\");\n",
              "\n",
              "            // Reset highlights superimposed over tokens\n",
              "            svg.selectAll(\".attentionBoxes\")\n",
              "                .selectAll(\"g\")\n",
              "                .selectAll(\"rect\")\n",
              "                .style(\"opacity\", 0.0);\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function renderAttention(svg, attention) {\n",
              "\n",
              "        // Remove previous dom elements\n",
              "        svg.select(\"#attention\").remove();\n",
              "\n",
              "        // Add new elements\n",
              "        svg.append(\"g\")\n",
              "            .attr(\"id\", \"attention\") // Container for all attention arcs\n",
              "            .selectAll(\".headAttention\")\n",
              "            .data(attention)\n",
              "            .enter()\n",
              "            .append(\"g\")\n",
              "            .classed(\"headAttention\", true) // Group attention arcs by head\n",
              "            .attr(\"head-index\", (d, i) => i)\n",
              "            .selectAll(\".tokenAttention\")\n",
              "            .data(d => d)\n",
              "            .enter()\n",
              "            .append(\"g\")\n",
              "            .classed(\"tokenAttention\", true) // Group attention arcs by left token\n",
              "            .attr(\"left-token-index\", (d, i) => i)\n",
              "            .selectAll(\"line\")\n",
              "            .data(d => d)\n",
              "            .enter()\n",
              "            .append(\"line\")\n",
              "            .attr(\"x1\", BOXWIDTH)\n",
              "            .attr(\"y1\", function () {\n",
              "                const leftTokenIndex = +this.parentNode.getAttribute(\"left-token-index\")\n",
              "                return TEXT_TOP + leftTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2)\n",
              "            })\n",
              "            .attr(\"x2\", BOXWIDTH + MATRIX_WIDTH)\n",
              "            .attr(\"y2\", (d, rightTokenIndex) => TEXT_TOP + rightTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2))\n",
              "            .attr(\"stroke-width\", 2)\n",
              "            .attr(\"stroke\", function () {\n",
              "                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n",
              "                return headColors(headIndex)\n",
              "            })\n",
              "            .attr(\"left-token-index\", function () {\n",
              "                return +this.parentNode.getAttribute(\"left-token-index\")\n",
              "            })\n",
              "            .attr(\"right-token-index\", (d, i) => i)\n",
              "        ;\n",
              "        updateAttention(svg)\n",
              "    }\n",
              "\n",
              "    function updateAttention(svg) {\n",
              "        svg.select(\"#attention\")\n",
              "            .selectAll(\"line\")\n",
              "            .attr(\"stroke-opacity\", function (d) {\n",
              "                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n",
              "                // If head is selected\n",
              "                if (config.headVis[headIndex]) {\n",
              "                    // Set opacity to attention weight divided by number of active heads\n",
              "                    return d / activeHeads()\n",
              "                } else {\n",
              "                    return 0.0;\n",
              "                }\n",
              "            })\n",
              "    }\n",
              "\n",
              "    function boxOffsets(i) {\n",
              "        const numHeadsAbove = config.headVis.reduce(\n",
              "            function (acc, val, cur) {\n",
              "                return val && cur < i ? acc + 1 : acc;\n",
              "            }, 0);\n",
              "        return numHeadsAbove * (BOXWIDTH / activeHeads());\n",
              "    }\n",
              "\n",
              "    function activeHeads() {\n",
              "        return config.headVis.reduce(function (acc, val) {\n",
              "            return val ? acc + 1 : acc;\n",
              "        }, 0);\n",
              "    }\n",
              "\n",
              "    function drawCheckboxes(top, svg) {\n",
              "        const checkboxContainer = svg.append(\"g\");\n",
              "        const checkbox = checkboxContainer.selectAll(\"rect\")\n",
              "            .data(config.headVis)\n",
              "            .enter()\n",
              "            .append(\"rect\")\n",
              "            .attr(\"fill\", (d, i) => headColors(i))\n",
              "            .attr(\"x\", (d, i) => i * CHECKBOX_SIZE)\n",
              "            .attr(\"y\", top)\n",
              "            .attr(\"width\", CHECKBOX_SIZE)\n",
              "            .attr(\"height\", CHECKBOX_SIZE);\n",
              "\n",
              "        function updateCheckboxes() {\n",
              "            checkboxContainer.selectAll(\"rect\")\n",
              "                .data(config.headVis)\n",
              "                .attr(\"fill\", (d, i) => d ? headColors(i): lighten(headColors(i)));\n",
              "        }\n",
              "\n",
              "        updateCheckboxes();\n",
              "\n",
              "        checkbox.on(\"click\", function (d, i) {\n",
              "            if (config.headVis[i] && activeHeads() === 1) return;\n",
              "            config.headVis[i] = !config.headVis[i];\n",
              "            updateCheckboxes();\n",
              "            updateAttention(svg);\n",
              "        });\n",
              "\n",
              "        checkbox.on(\"dblclick\", function (d, i) {\n",
              "            // If we double click on the only active head then reset\n",
              "            if (config.headVis[i] && activeHeads() === 1) {\n",
              "                config.headVis = new Array(config.nHeads).fill(true);\n",
              "            } else {\n",
              "                config.headVis = new Array(config.nHeads).fill(false);\n",
              "                config.headVis[i] = true;\n",
              "            }\n",
              "            updateCheckboxes();\n",
              "            updateAttention(svg);\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function lighten(color) {\n",
              "        const c = d3.hsl(color);\n",
              "        const increment = (1 - c.l) * 0.6;\n",
              "        c.l += increment;\n",
              "        c.s -= increment;\n",
              "        return c;\n",
              "    }\n",
              "\n",
              "    function transpose(mat) {\n",
              "        return mat[0].map(function (col, i) {\n",
              "            return mat.map(function (row) {\n",
              "                return row[i];\n",
              "            });\n",
              "        });\n",
              "    }\n",
              "\n",
              "});"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('myBERT')"
      ],
      "metadata": {
        "id": "j1vYN2zQDl2r"
      },
      "execution_count": 69,
      "outputs": []
    }
  ]
}